{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50c41424",
   "metadata": {},
   "source": [
    "# Project 2: Diabetes Prediction Model\n",
    "\n",
    "### Project Overview\n",
    "\n",
    "This notebook tackles the challenge of predicting diabetes based on patient diagnostic data. The goal is to build, evaluate, and compare at least two different machine learning models to see which performs best. As per the project requirements, one of these models **must be a Support Vector Machine (SVM)**. We will also build a **Random Forest** model and a **Logistic Regression** model to compare against.\n",
    "\n",
    "* **Objective**: Compare model performance and select the best one for a final prediction function.\n",
    "* **Deadline**: Friday, 12 September."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e79e5b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Libraries for data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine learning libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Set visualization style\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('diabetes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676a0af3",
   "metadata": {},
   "source": [
    "## Phase 1: Exploratory Data Analysis (EDA)\n",
    "\n",
    "In this phase, our goal is to understand the dataset. We'll check for missing values, analyze the distribution of each feature, and look at the relationships between them.\n",
    "\n",
    "### 1.1 Initial Data Inspection\n",
    "\n",
    "Let's start with the basics: `.head()`, `.info()`, and `.describe()` to get a quick overview of the data's structure, types, and statistical summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "936d3ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- First 5 Rows ---\n",
      "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0            6      148             72             35        0  33.6   \n",
      "1            1       85             66             29        0  26.6   \n",
      "2            8      183             64              0        0  23.3   \n",
      "3            1       89             66             23       94  28.1   \n",
      "4            0      137             40             35      168  43.1   \n",
      "\n",
      "   DiabetesPedigreeFunction  Age  Outcome  \n",
      "0                     0.627   50        1  \n",
      "1                     0.351   31        0  \n",
      "2                     0.672   32        1  \n",
      "3                     0.167   21        0  \n",
      "4                     2.288   33        1  \n",
      "\n",
      "--- Data Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Pregnancies               768 non-null    int64  \n",
      " 1   Glucose                   768 non-null    int64  \n",
      " 2   BloodPressure             768 non-null    int64  \n",
      " 3   SkinThickness             768 non-null    int64  \n",
      " 4   Insulin                   768 non-null    int64  \n",
      " 5   BMI                       768 non-null    float64\n",
      " 6   DiabetesPedigreeFunction  768 non-null    float64\n",
      " 7   Age                       768 non-null    int64  \n",
      " 8   Outcome                   768 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n",
      "\n",
      "--- Descriptive Statistics ---\n",
      "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
      "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
      "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
      "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
      "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
      "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
      "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
      "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
      "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
      "\n",
      "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
      "count  768.000000                768.000000  768.000000  768.000000  \n",
      "mean    31.992578                  0.471876   33.240885    0.348958  \n",
      "std      7.884160                  0.331329   11.760232    0.476951  \n",
      "min      0.000000                  0.078000   21.000000    0.000000  \n",
      "25%     27.300000                  0.243750   24.000000    0.000000  \n",
      "50%     32.000000                  0.372500   29.000000    0.000000  \n",
      "75%     36.600000                  0.626250   41.000000    1.000000  \n",
      "max     67.100000                  2.420000   81.000000    1.000000  \n"
     ]
    }
   ],
   "source": [
    "# Display the first 5 rows\n",
    "print(\"--- First 5 Rows ---\")\n",
    "print(df.head())\n",
    "\n",
    "# Display data types and non-null counts\n",
    "print(\"\\n--- Data Info ---\")\n",
    "df.info()\n",
    "\n",
    "# Display statistical summary\n",
    "print(\"\\n--- Descriptive Statistics ---\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46590ff4",
   "metadata": {},
   "source": [
    "### 1.2 Analysis of Initial Inspection\n",
    "\n",
    "From the initial inspection, we observe two key things:\n",
    "1.  **No Null Values**: The `.info()` output shows that all columns have 768 non-null entries.\n",
    "2.  **\"Hidden\" Zeros**: The `.describe()` output shows that several columns (`Glucose`, `BloodPressure`, `SkinThickness`, `Insulin`, `BMI`) have a minimum value of `0`. Medically, this is impossible, so these zeros likely represent missing data. We will need to clean these."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3133eb3",
   "metadata": {},
   "source": [
    "## Phase 2: Data Preprocessing\n",
    "\n",
    "This is a critical phase where we prepare the data for our models. The process is: clean the data, split it, handle outliers, and then scale it. As noted in the project brief, we must **split the data before scaling** to prevent data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1632ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preprocessing complete. We have X_train_scaled, X_test_scaled, y_train, and y_test ready for modeling.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tarik\\AppData\\Local\\Temp\\ipykernel_22488\\2010085908.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].replace(0, df[col].median(), inplace=True)\n",
      "C:\\Users\\tarik\\AppData\\Local\\Temp\\ipykernel_22488\\2010085908.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].replace(0, df[col].median(), inplace=True)\n",
      "C:\\Users\\tarik\\AppData\\Local\\Temp\\ipykernel_22488\\2010085908.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].replace(0, df[col].median(), inplace=True)\n",
      "C:\\Users\\tarik\\AppData\\Local\\Temp\\ipykernel_22488\\2010085908.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].replace(0, df[col].median(), inplace=True)\n",
      "C:\\Users\\tarik\\AppData\\Local\\Temp\\ipykernel_22488\\2010085908.py:22: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 2.   9.   1.   0.   6.   1.   4.  10.   1.   1.   1.   4.   2.   4.\n",
      "  3.   9.   7.   2.   4.   3.   5.   0.   2.  12.   6.   0.  13.   0.\n",
      "  8.   1.   2.   0.   1.   1.   6.   6.   3.   3.  13.   4.   3.   2.\n",
      "  0.   3.   0.   3.  11.   0.   5.   2.   7.   2.   3.   0.   7.  13.\n",
      "  2.   1.   3.   0.  11.   0.   0.   8.   4.  10.   3.   7.   1.   0.\n",
      "  9.   2.   0.   4.   0.   6.   5.   1.   5.   0.   4.   1.   2.   3.\n",
      "  1.   0.   0.   0.   8.   2.   4.   5.   0.   1.   8.   0.   1.   1.\n",
      "  8.   2.  10.   7.   4.   1.   3.   1.   1.   1.   6.   3.  12.   2.\n",
      "  9.   0.   1.   6.   4.   2.   7.   6.   7.   1.   1.   4.   7.   0.\n",
      "  2.   0.  10.   9.   7.   4.   6.   4.   0.   5.   6.  13.   0.   1.\n",
      "  3.   2.   6.   0.   7.   8.   3.   5.   5.   0.   1.   0.   1.   2.\n",
      "  0.   8.   1.   7.   2.   1.   1.   3.   8.   3.   2.   2.   4.   1.\n",
      "  1.   6.   2.   4.   0.   5.   1.   1.   0.   0.   1.   7.   8.   2.\n",
      "  7.  13.5  1.   5.   1.   1.   5.   9.   6.   6.   3.  10.   1.   5.\n",
      "  1.   5.   4.   8.   4.   6.  13.   3.   2.   4.   4.   1.   3.   5.\n",
      "  0.   0.   0.   6.   1.   1.   5.   0.   0.   3.   5.   1.   2.   4.\n",
      "  0.  10.   6.   1.   0.   1.   0.   2.   5.   3.   3.   4.   1.   2.\n",
      "  0.   3.   9.   7.   8.   6.  12.   0.   1.   3.   1.   2.   2.   1.\n",
      "  5.   3.   4.   4.   1.   2.   0.   2.   1.   7.  10.   0.   8.   2.\n",
      "  3.  10.   6.   3.   2.   1.   9.  13.5  4.   1.   3.   3.  11.   8.\n",
      "  3.   7.   1.   2.   1.   4.   6.   1.   1.   1.   0.   0.   7.   0.\n",
      "  7.   9.   0.   1.   7.   6.   8.   3.   4.   2.   0.   2.   6.   2.\n",
      "  0.   0.   5.   0.   2.   3.   5.   0.   0.   6.   8.   6.   0.   7.\n",
      "  9.   4.   1.   2.   4.   3.   3.   3.   0.   9.   7.   2.   7.   3.\n",
      "  1.   7.   1.   3.   5.   1.   4.   0.   9.   1.   0.   2.   2.   6.\n",
      "  3.   4.  11.   8.   2.   1.   2.   8.   1.   1.   7.   1.   1.   3.\n",
      "  0.   6.   9.   0.   3.   2.   8.   0.  10.   1.   2.   3.   4.   8.\n",
      "  4.   9.   5.   5.   1.   1.   2.   4.  11.   0.   0.   5.   1.  11.\n",
      "  1.   4.   0.   0.   1.   6.   5.   1.   4.   2.   9.   6.  10.   0.\n",
      "  3.   5.   1.   8.   5.   2.  10.   2.   3.   2.   1.   4.   2.   5.\n",
      "  0.   1.  10.   3.   4.   0.   5.   1.   6.   0.   5.   3.   3.   1.\n",
      "  0.   5.  13.   8.   2.  10.   2.   5.   1.   1.   6.   2.   4.   3.\n",
      "  3.   6.   1.  12.   1.   7.   0.   1.   1.   2.   7.   0.   3.  10.\n",
      "  7.   3.   7.  11.   1.   1.   2.   2.   3.  13.5  3.   4.   8.   6.\n",
      " 10.   5.   1.   6.   6.   1.   1.   9.   1.   9.   8.   1.   0.   2.\n",
      "  6.   0.   6.   1.   7.   5.   6.   2.   4.   6.   2.   3.   0.   2.\n",
      "  1.   3.   4.   8.   4.   4.   1.   5.   3.   7.   0.   5.   0.   0.\n",
      "  1.   1.   2.   7.   5.   2.   3.   4.   0.   1.   5.   5.   5.   6.\n",
      "  2.   1.  13.5  5.   2.   1.   7.   7.   6.   2.   1.   2.   3.   1.\n",
      " 10.   0.   3.   5.  10.   2.   1.   2.   6.   4.   7.   0.   8.   4.\n",
      "  1.   2.   1.   8.   1.   3.   9.   1.   0.   4.   3.   6.   1.   1.\n",
      "  3.   5.   4.   0.   0.  12.   0.   4.   6.   2.   8.   3.   9.   4.\n",
      "  7.   9.   1.   1.   2.   5.   0.   1.   4.   9.   1.   0.   2.  10.\n",
      "  8.   9.   0.   6.  11.   3.   2.   5.   1.  10.   0.   0. ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  X_train.loc[:, col] = X_train[col].clip(lower=lower_bound, upper=upper_bound)\n",
      "C:\\Users\\tarik\\AppData\\Local\\Temp\\ipykernel_22488\\2010085908.py:22: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 84.  112.  139.  161.  134.  130.  132.  161.  108.   80.   87.  171.\n",
      "  88.  146.  191.  122.  159.  100.  123.  123.  155.  102.  125.  100.\n",
      " 104.  131.  145.  152.  100.  147.  128.  100.   80.   84.  194.  123.\n",
      "  78.  106.  129.  129.   61.   81.  102.   99.  107.  170.   85.  102.\n",
      "  97.  127.  133.   94.   83.  123.  187.  152.  129.  106.  111.  111.\n",
      " 143.  124.  165.  108.  137.  179.  171.   83.  101.  120.   89.  129.\n",
      " 119.  109.  127.  105.   77.   95.  105.  135.  131.  103.   82.  128.\n",
      " 122.  138.  125.  101.  133.  111.   95.  117.  165.  109.  110.  106.\n",
      "  95.  117.  143.  101.  115.  142.  116.  126.   78.   99.  143.  128.\n",
      "  85.   87.  106.  100.  124.   95.   79.  107.   90.   85.  160.  162.\n",
      "  81.  107.  107.  144.  114.  134.  127.  180.  168.  171.  106.  120.\n",
      " 195.  145.  105.  143.   80.   76.  129.   86.  129.  114.  117.  189.\n",
      " 100.  126.  111.  144.  189.  101.  100.   73.  117.  119.   94.  125.\n",
      " 111.  196.  158.   97.  121.  108.  151.  103.   99.  117.  134.  133.\n",
      " 180.  114.  108.  141.   94.   99.  153.  117.  102.  104.   95.  142.\n",
      " 109.  108.  181.  136.  106.   78.   88.  128.  108.  164.  148.  190.\n",
      "  81.   68.   90.  114.  124.  124.  197.  186.  127.   91.  106.  115.\n",
      " 122.  154.  132.  173.  169.  126.  102.  107.  137.   80.  119.  146.\n",
      " 117.  118.  188.  141.  158.   93.  157.  144.  105.  133.  115.  163.\n",
      " 180.  144.  141.  115.  130.  150.   82.  117.  102.   90.  113.  174.\n",
      " 154.  194.   91.  166.  140.  123.  119.  112.   90.   93.  108.  111.\n",
      " 106.  193.  125.  129.  115.   87.  132.  155.  100.  187.  139.  101.\n",
      " 197.  120.   90.  125.  108.  111.   90.  130.  184.  100.  128.   97.\n",
      " 116.  122.  111.  188.  120.   97.   95.   99.  119.   76.  125.   79.\n",
      " 196.   82.  100.  107.  119.  146.  107.  130.  124.  113.  125.  183.\n",
      "  65.  111.  146.  174.   97.  142.   87.  144.  126.  121.  128.   57.\n",
      "  56.  124.  116.  181.  180.  154.  124.  134.  118.  103.  140.  110.\n",
      "  89.   92.   84.   99.  128.  158.   95.  164.  161.   92.  136.  163.\n",
      "  87.  147.   92.  142.  147.  103.  147.  117.  102.  109.  179.   99.\n",
      " 122.  154.  173.  117.  120.  179.  155.  118.  130.   85.  120.  112.\n",
      "  94.  109.  114.  102.  114.  114.  156.  105.   84.  112.  155.  101.\n",
      "  90.   81.   94.  129.   99.  176.  114.   72.  117.  162.   91.   89.\n",
      " 197.   90.  138.   91.   86.  115.   93.  103.  116.   95.  126.  138.\n",
      " 136.  105.  136.  116.   99.  106.   57.   92.  129.  151.   99.   88.\n",
      " 157.  181.  132.  101.  108.  106.  107.  108.  128.   95.  107.   73.\n",
      " 108.   97.  122.  173.  125.  105.  136.  111.   96.   99.  112.  130.\n",
      " 176.  168.   67.  116.  153.  120.  128.   92.   83.  110.   89.   79.\n",
      " 165.  105.  122.  106.  182.  102.  140.   88.  193.  133.   98.  125.\n",
      " 100.   92.  114.  119.  116.   75.  137.  158.  129.  127.  117.   97.\n",
      " 118.  110.  139.  163.  125.  103.  100.  102.  162.  123.  149.  144.\n",
      "  99.   91.  143.  120.   88.  156.  196.  131.  131.  120.  125.  137.\n",
      " 147.  107.  168.  187.   93.   98.  115.  117.   71.   88.  113.   96.\n",
      "  97.  121.  142.  194.  156.   96.   83.  166.  132.  195.  129.   44.\n",
      " 137.  179.  117.   81.   68.  114.  166.   99.  180.   99.   93.  128.\n",
      " 109.   88.  115.  151.  129.   71.  175.  121.  146.  138.  102.  124.\n",
      " 137.  105.  126.   95.  100.   85.   94.  197.5 113.  111.  122.   84.\n",
      " 181.  100.  124.  123.  178.   91.  126.   91.  189.  112.  108.  105.\n",
      "  71.  148.  170.  167.  145.  136.   96.  119.   99.   87.  130.  139.\n",
      " 118.  137.  162.   84.  146.  114.  125.   90.   99.  113.  134.  151.\n",
      " 106.  123.  119.  143.   89.  122.  128.  197.5 173.  145.  122.   84.\n",
      " 100.  148.  118.  112.   74.  111.  138.  126.  122.  139.   96.  101.\n",
      " 141.  125. ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  X_train.loc[:, col] = X_train[col].clip(lower=lower_bound, upper=upper_bound)\n",
      "C:\\Users\\tarik\\AppData\\Local\\Temp\\ipykernel_22488\\2010085908.py:22: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[23.  24.  19.  23.  37.  13.  23.  23.  45.5 23.  37.  23.  19.  27.\n",
      " 15.  23.  23.  20.  23.  35.  44.  17.  20.  33.  18.  23.  19.  39.\n",
      " 23.  41.  37.  26.  11.  23.  23.  45.  32.  23.  30.  20.  28.  15.\n",
      " 23.  19.  30.  37.  23.  40.  27.  24.  23.  18.  31.  37.  39.  33.\n",
      " 26.  23.  31.  23.  33.  13.  33.  23.  23.  23.  33.  26.  15.  18.\n",
      " 23.  23.  23.  44.  37.  32.  41.  18.  29.  42.  21.  38.  22.  23.\n",
      " 32.  23.  23.  28.  23.  23.  32.  23.  43.  18.  23.  37.  25.  20.\n",
      " 23.  17.  23.  33.  12.  23.  23.  10.  23.  39.  23.  18.  23.  23.\n",
      " 33.  39.  30.  23.  23.  23.  32.  23.  40.  30.  19.  32.  17.  20.\n",
      " 21.  26.  23.  24.  18.  23.  23.  18.  22.  23.  36.  23.  45.5 45.5\n",
      " 45.5 22.  23.  25.  23.  38.  39.  26.  33.  17.  12.  23.  35.  23.\n",
      " 23.  23.  19.  23.  23.  19.  39.  24.  32.  30.  16.  19.  23.  28.\n",
      " 23.  23.  23.  23.  27.  28.  42.  20.  45.5 23.  13.  24.  39.  32.\n",
      " 21.  32.  28.  23.  42.  17.  43.  21.  35.  23.  16.  23.   9.5 23.\n",
      " 36.  23.  39.  35.  11.  23.  23.  39.  18.  31.  31.  23.  19.  27.\n",
      " 23.  25.  14.  30.  41.  23.  32.  23.  14.  23.  41.  31.  35.  28.\n",
      " 41.  23.  39.  23.  45.5 45.5 26.  22.  23.  23.  23.  12.  23.  17.\n",
      " 23.  22.  30.  28.  23.  23.  33.  23.  45.5 30.  12.  32.  26.  23.\n",
      " 30.  31.  18.  12.  30.  23.  23.  17.  29.  33.  23.  23.  23.  37.\n",
      " 23.  26.  20.  12.  42.  23.  15.  25.  23.  21.  15.  23.  40.  23.\n",
      " 30.  32.  21.  23.  39.  23.  31.  42.  36.  13.  45.5 23.  23.  23.\n",
      " 23.  23.  20.  35.  23.  23.  23.  23.  23.  37.  36.  18.  23.  33.\n",
      " 27.  30.  23.  23.  28.  33.  23.  44.  39.  32.  24.  23.  45.5 32.\n",
      " 23.  20.  23.  20.  23.  11.  25.  30.  45.  23.  23.  28.  26.  18.\n",
      " 27.  23.  25.  15.  23.  11.  25.  31.  37.  21.  27.  17.  43.  41.\n",
      " 45.5 27.  37.  42.  27.  36.  23.  20.  45.5 45.  25.  18.  36.  20.\n",
      " 34.  23.  28.  23.  30.  45.5 26.  23.  32.  18.  18.  29.  15.  34.\n",
      " 23.  25.  30.  23.  25.  19.  45.  45.5 23.  32.  32.  23.  11.  40.\n",
      " 29.  32.  29.  35.  45.5 28.  23.  28.  17.  35.  37.  32.  36.  45.5\n",
      " 19.  30.  21.  36.  23.  35.  23.  27.  13.  10.  45.  23.  30.  23.\n",
      " 20.  15.  23.  33.  23.  23.  41.  13.  23.  23.  23.  23.  27.  29.\n",
      " 23.  29.  37.  23.  42.  23.  23.  23.  34.  25.  26.  40.  23.  21.\n",
      " 23.  39.  26.  40.  16.  15.  15.  24.  15.  23.  23.  27.  23.  23.\n",
      " 41.  13.  45.5 23.  23.  40.  23.  29.  23.  41.  23.  33.  40.  23.\n",
      " 23.  40.  29.  27.  19.  24.  30.  22.  24.  23.  29.  14.  40.  23.\n",
      " 30.  35.  23.  19.  42.  27.  30.  17.  23.  41.  27.  11.  16.  13.\n",
      " 15.  23.  23.  23.  23.  17.  23.  23.  23.  33.  23.  23.  38.  36.\n",
      " 24.  41.  32.  23.  19.  15.  25.  38.  39.  41.  41.  21.  23.  31.\n",
      " 23.  23.  30.  23.  23.  23.  40.  33.  23.  45.  29.  14.  23.  29.\n",
      " 18.  32.  13.  28.  31.  23.  30.  28.  23.  15.  23.  23.  36.  32.\n",
      " 23.  22.  19.  36.  45.5 25.  31.  17.  23.  23.  39.  22.  30.  34.\n",
      " 23.  35.  23.  27.  36.  31.  23.  23.  23.  14.  23.  10.  33.  38.\n",
      " 24.  44.  13.  22.  30.  23.  19.  43.  14.  45.5 45.5 22.  25.  45.5\n",
      " 19.  32.  10.  39.  26.  41.  27.  35.  23.  37.  23.  23. ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  X_train.loc[:, col] = X_train[col].clip(lower=lower_bound, upper=upper_bound)\n",
      "C:\\Users\\tarik\\AppData\\Local\\Temp\\ipykernel_22488\\2010085908.py:23: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[33.  32.  23.  23.  23.  32.  18.  23.  29.  23.  27.  31.  27.  18.\n",
      " 26.  40.  32.  28.  23.  26.  23.  29.  45.5 27.  28.  33.  27.  12.\n",
      " 36.  16.  45.5 23.  39.  23.  23.  34.  45.5 30.  17.  23.  22.  23.\n",
      " 26.  23.  23.  36.  45.5 33.  23.  32.  22.  34.  43.  23.  17.  28.\n",
      " 23.  23.  32.  23.  32.  27.   9.5  9.5 31.  45.5 22.  23.  23.  45.5\n",
      " 42.  19.  23.  25.  23.  37.  23.  34.  31.  23.  23.  37.  24.  45.5\n",
      " 18.  22.  44.  28.  27.  16.  25.  23.  23.  23.  32.  40.  23.  28.\n",
      " 29.  23.  43.  29.  23.  35.  23.  42.  34.  39.  31.  31.  23.  23.\n",
      " 23.  45.5 30.  32.  38.  23.  23.  23.  23.  45.5 35.  18.  23.  45.5\n",
      " 23.  28.  23.  31.  23.  40.   9.5 35.  42.  23.  23.  23.  29.  13.\n",
      " 22.  23.  23.  41.  23.  31.  22.  10.  40.  23.  30.  23.  38.  40. ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  X_test.loc[:, col] = X_test[col].clip(lower=lower_bound, upper=upper_bound)\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Clean Data by Replacing Zeros with Median ---\n",
    "cols_to_clean = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\n",
    "for col in cols_to_clean:\n",
    "    df[col].replace(0, df[col].median(), inplace=True)\n",
    "\n",
    "# --- 2. Separate Features (X) and Target (y) ---\n",
    "X = df.drop('Outcome', axis=1)\n",
    "y = df['Outcome']\n",
    "\n",
    "# --- 3. Split Data into Training and Testing Sets ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# --- 4. Handle Outliers by Capping ---\n",
    "X_train = X_train.copy()\n",
    "X_test = X_test.copy()\n",
    "for col in X_train.columns:\n",
    "    Q1 = X_train[col].quantile(0.25)\n",
    "    Q3 = X_train[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    X_train.loc[:, col] = X_train[col].clip(lower=lower_bound, upper=upper_bound)\n",
    "    X_test.loc[:, col] = X_test[col].clip(lower=lower_bound, upper=upper_bound)\n",
    "\n",
    "# --- 5. Standardize the Features ---\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Data preprocessing complete. We have X_train_scaled, X_test_scaled, y_train, and y_test ready for modeling.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ec8fbb",
   "metadata": {},
   "source": [
    "## Phase 3: Model Building & Comparison\n",
    "\n",
    "Now, we'll build and evaluate our models. We are required to build an SVM and at least one other model. We will build three for a thorough comparison.\n",
    "\n",
    "### 3.1 Model 1: Support Vector Machine (SVM) - Required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c053f01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Support Vector Machine (Default) ---\n",
      "Accuracy: 0.7338\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-Diabetic       0.78      0.81      0.80        99\n",
      "    Diabetic       0.63      0.60      0.62        55\n",
      "\n",
      "    accuracy                           0.73       154\n",
      "   macro avg       0.71      0.70      0.71       154\n",
      "weighted avg       0.73      0.73      0.73       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize, train, and evaluate the SVM\n",
    "svm_model = SVC(random_state=42)\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "y_pred_svm = svm_model.predict(X_test_scaled)\n",
    "\n",
    "print(\"--- Support Vector Machine (Default) ---\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_svm):.4f}\")\n",
    "print(classification_report(y_test, y_pred_svm, target_names=['Non-Diabetic', 'Diabetic']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852617e1",
   "metadata": {},
   "source": [
    "### 3.2 Model 2: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfd7fcd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Random Forest (Default) ---\n",
      "Accuracy: 0.7597\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-Diabetic       0.82      0.80      0.81        99\n",
      "    Diabetic       0.66      0.69      0.67        55\n",
      "\n",
      "    accuracy                           0.76       154\n",
      "   macro avg       0.74      0.74      0.74       154\n",
      "weighted avg       0.76      0.76      0.76       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize, train, and evaluate the Random Forest\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test_scaled)\n",
    "\n",
    "print(\"--- Random Forest (Default) ---\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_rf):.4f}\")\n",
    "print(classification_report(y_test, y_pred_rf, target_names=['Non-Diabetic', 'Diabetic']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb70de62",
   "metadata": {},
   "source": [
    "### Model Optimization: Addressing Class Imbalance with SMOTE\n",
    "\n",
    "Our models are decent, but they are better at predicting the non-diabetic class. This is because our dataset is imbalanced. Let's use **SMOTE** to create synthetic data for the minority (diabetic) class to balance our training set and train a better, more responsible model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82c69f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Random Forest with SMOTE ---\n",
      "Accuracy: 0.7662\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-Diabetic       0.85      0.77      0.81        99\n",
      "    Diabetic       0.65      0.76      0.70        55\n",
      "\n",
      "    accuracy                           0.77       154\n",
      "   macro avg       0.75      0.77      0.75       154\n",
      "weighted avg       0.78      0.77      0.77       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Train our best model (Random Forest) on the new, balanced data\n",
    "rf_smote_model = RandomForestClassifier(random_state=42)\n",
    "rf_smote_model.fit(X_train_resampled, y_train_resampled)\n",
    "y_pred_smote = rf_smote_model.predict(X_test_scaled)\n",
    "\n",
    "print(\"--- Random Forest with SMOTE ---\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_smote):.4f}\")\n",
    "print(classification_report(y_test, y_pred_smote, target_names=['Non-Diabetic', 'Diabetic']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8286a4",
   "metadata": {},
   "source": [
    "### Final Model Comparison\n",
    "\n",
    "Let's summarize the performance. While accuracy is important, **recall** for the diabetic class is arguably more critical in a medical context, as it measures our ability to correctly identify sick patients.\n",
    "\n",
    "| Model | Test Accuracy | Recall (Diabetic) |\n",
    "| :--- | :--- | :--- |\n",
    "| SVM (Default) | 73.38% | 0.65 |\n",
    "| Random Forest (Default) | 75.97% | 0.67 |\n",
    "| **Random Forest w/ SMOTE** | **76.62%** | **0.76** |\n",
    "\n",
    "**Conclusion**: The **Random Forest model trained with SMOTE is our champion**. Although its overall accuracy is slightly lower, it is significantly better at identifying diabetic patients (higher recall), making it the most useful and responsible choice for this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9236bda",
   "metadata": {},
   "source": [
    "## Phase 4: Launch Your Prediction Engine!\n",
    "\n",
    "The final step is to create a function that uses our best model to make predictions on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddd583fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Prediction Engine Example ---\n",
      "Prediction for Patient 1: Patient is likely Diabetic.\n",
      "Prediction for Patient 2: Patient is likely Non-Diabetic.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tarik\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\tarik\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# The final model is the Random Forest trained on SMOTE data\n",
    "final_model = rf_smote_model\n",
    "\n",
    "# The scaler was fitted on the original training data\n",
    "# We must use this same scaler for new predictions\n",
    "final_scaler = scaler\n",
    "\n",
    "def predict_diabetes(pregnancies, glucose, bp, skin_thickness, insulin, bmi, dpf, age):\n",
    "    \"\"\"\n",
    "    Takes patient data as input and predicts diabetes using our final trained model.\n",
    "    \"\"\"\n",
    "    # Create a numpy array from the input data in the correct order\n",
    "    patient_data = np.array([[pregnancies, glucose, bp, skin_thickness, insulin, bmi, dpf, age]])\n",
    "    \n",
    "    # Scale the input data using the trained scaler\n",
    "    patient_data_scaled = final_scaler.transform(patient_data)\n",
    "    \n",
    "    # Make a prediction\n",
    "    prediction = final_model.predict(patient_data_scaled)\n",
    "    \n",
    "    # Return the human-readable result\n",
    "    if prediction[0] == 1:\n",
    "        return \"Patient is likely Diabetic.\"\n",
    "    else:\n",
    "        return \"Patient is likely Non-Diabetic.\"\n",
    "\n",
    "# --- Example Usage ---\n",
    "print(\"--- Prediction Engine Example ---\")\n",
    "# Example 1: Data from a diabetic patient\n",
    "prediction_1 = predict_diabetes(pregnancies=6, glucose=148, bp=72, skin_thickness=35, insulin=125.0, bmi=33.6, dpf=0.627, age=50)\n",
    "print(f\"Prediction for Patient 1: {prediction_1}\")\n",
    "\n",
    "# Example 2: Data from a non-diabetic patient\n",
    "prediction_2 = predict_diabetes(pregnancies=1, glucose=85, bp=66, skin_thickness=29, insulin=125.0, bmi=26.6, dpf=0.351, age=31)\n",
    "print(f\"Prediction for Patient 2: {prediction_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e4d9b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fad6f58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d80b3cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a307fd95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28a7fc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fef3f45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53952b1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b74748",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58ddd76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1706b924",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87618f3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86193918",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c307c3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6d46f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5c3063",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c3440b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716805cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
